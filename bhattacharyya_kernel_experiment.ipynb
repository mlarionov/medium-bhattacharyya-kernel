{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fa8d0e2",
   "metadata": {},
   "source": [
    "# Learning on sets using the Bhattacharyya kernel\n",
    "\n",
    "In this experiment, we test the expressivity of the model based on the Bhattacharyya kernel. \n",
    "Our plan is to create 1000 sets of numbers. Each set generated using Normal distribution with random parameters.\n",
    "\n",
    "The task is to predict if the 60% quantile is greater or less than the specified value. \n",
    "In order to do that we first fit Normal distribution for each set, and then compute the Bhattacharyya kernel matrix based on the inferred parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f0695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e5349ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sets = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd51420c",
   "metadata": {},
   "source": [
    "We will randomly select sample size, mean and std for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "267da745",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mu = -1.0\n",
    "max_mu = 1.0\n",
    "min_std = 0.1\n",
    "max_std = 0.9\n",
    "min_size = 5\n",
    "max_size = 50\n",
    "quantile = 0.6\n",
    "quantile_comparison = max_mu * 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "110550e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2128506)\n",
    "data = pd.DataFrame({\n",
    "    \"mu\": np.random.uniform(min_mu, max_mu, n_sets),\n",
    "    \"sigma\": np.random.uniform(min_std, max_std, n_sets),\n",
    "    \"size\": np.random.randint(min_size, max_size, n_sets)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb4e4b2",
   "metadata": {},
   "source": [
    "Now we take samples of the distributions in each sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92217ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [np.random.normal(data.loc[i, \"mu\"], data.loc[i, \"sigma\"], data.loc[i, \"size\"]) for i in range(n_sets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6daa1280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the target field\n",
    "quantile_values = np.array([np.quantile(sample, quantile) for sample in samples])\n",
    "data['target'] = quantile_values - quantile_comparison > 0\n",
    "data['target'] = data.target.astype(\"int\")\n",
    "# Fit the Normal distribution\n",
    "data[\"x_bar\"] = [np.mean(sample) for sample in samples]\n",
    "data[\"s\"] = [np.std(sample, ddof=1) for sample in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c5cc481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mu</th>\n",
       "      <th>sigma</th>\n",
       "      <th>size</th>\n",
       "      <th>target</th>\n",
       "      <th>x_bar</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.141728</td>\n",
       "      <td>0.586581</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.154003</td>\n",
       "      <td>0.657748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.310797</td>\n",
       "      <td>0.727996</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.178226</td>\n",
       "      <td>0.536234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.098976</td>\n",
       "      <td>0.427965</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.223937</td>\n",
       "      <td>0.350883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.594182</td>\n",
       "      <td>0.276093</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.499583</td>\n",
       "      <td>0.211205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.027752</td>\n",
       "      <td>0.827064</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0.118751</td>\n",
       "      <td>0.809009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mu     sigma  size  target     x_bar         s\n",
       "0 -0.141728  0.586581    14       1  0.154003  0.657748\n",
       "1 -0.310797  0.727996    31       0 -0.178226  0.536234\n",
       "2 -0.098976  0.427965    10       0 -0.223937  0.350883\n",
       "3  0.594182  0.276093    19       1  0.499583  0.211205\n",
       "4 -0.027752  0.827064    47       1  0.118751  0.809009"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef7c919",
   "metadata": {},
   "source": [
    "The kernel function in this case can be computed analytically. The kernel function is given two arguments\n",
    "Let $m_1$ and $s_1$ are parameters of the first distribution and $m_1$ and $s_1$ - parameters of the second distribution.\n",
    "\n",
    "Then the Kernel is computed as:\n",
    "\n",
    "$$ K(m_1, s_1, m_2, s_2) = \\left(\\frac{1}{4} \\left(\\frac{s_1^2}{s_2^2} + \\frac{s_2^2}{s_1^2} + 2\\right)\\right)^{-\\frac{1}{4}} exp\\left(- \\frac{1}{4} \\frac{(m_1 - m_2)^2}{s_1^2 + s_2^2}\\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bfeccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define kernel function\n",
    "def kernel_function(row1, row2):\n",
    "    m1 = row1.x_bar\n",
    "    s1 = row1.s\n",
    "    m2 = row2.x_bar\n",
    "    s2 = row2.s\n",
    "    m1 = m1.values.reshape(-1, 1)\n",
    "    s1 = s1.values.reshape(-1, 1)\n",
    "    m2 = m2.values.reshape(1, -1)\n",
    "    s2 = s2.values.reshape(1, -1)\n",
    "    return (1/4*(s1**2/s2**2 + s2**2/s1**2 + 2))**(-1/4)\\\n",
    "        * np.exp(-1/4*(m1 - m2)**2/(s1**2+s2**2))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01d299c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, data[\"target\"], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44e44882",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel=kernel_function)\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d986afc",
   "metadata": {},
   "source": [
    "Model accuracy on training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e972fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9775"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb8da2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f46147",
   "metadata": {},
   "source": [
    "The accuracy is pretty high, but not 100% even on the training set. Using more general Probability Product Kernel may help to get more accuracy by tuning the hyperparameter $\\rho$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-medium-bhattacharyya-kernel] *",
   "language": "python",
   "name": "conda-env-.conda-medium-bhattacharyya-kernel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
